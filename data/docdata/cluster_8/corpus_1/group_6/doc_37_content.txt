Whether you view the description above as highly sentimental or grossly distorted probably depends on your feelings about credit cards. Love them or hate them, credit cards are part and parcel of most Americans' daily lives.  But how did the wallet-sized pieces of plastic come to play such a dominant role in consumer culture?  To answer that question, we can reach all the way back to the arrival of the colonists in the New World. They brought with them firmly established English laws regarding usury (the practice of lending money and charging interest, typically associated with high rates) and an inherent distrust for any concentration of power, especially in the banking industry.1  The first 'charge coins' began circulating around 1865 and were still being used up until the 1950s. They were made of celluloid, copper, aluminum or steel, and came in various shapes and sizes. They were mainly issued by department stores.2  The phrase 'credit card' first surfaced in 1887 as a way of describing a new way of paying for goods and services. This paved the way for the very first credit cards in the early 1900s. Sears Roebuck &amp;amp; Company was one of the first department stores to use 'merchant' or 'retail cards.'1  Other department stores and some oil companies began issuing dog-tag-style aluminum or metal plates, sometimes called 'Charga-Plates,' to customers. Sometimes they were kept in the store behind the counter. Today, they're considered collectibles.2  Gas credit cards arrived in 1924. Still, because these early cards had to be paid in full at each month's end and could only be used at the store of the issuer, they weren't widely used.1  The first non-retail credit card, the Diner's Club Card, appeared in 1949. It was truly unique in that it was the first card with universal purchasing power offered by a third party. (The cardboard card was the brainchild of a New York businessman who, after dining out with his wife at a local restaurant, realized he'd forgotten his wallet. Though his wife bailed him out, he resolved not to be caught in that dilemma again.)3 The Diner's Club Card at that time was limited to hotel, restaurant and air travel expenses, and, as with others like it, still required full balance payment at the end of the month.  Interestingly, even into the 1960s, many retail stores still wouldn't issue separate credit card accounts to married women, despite legal anti-discrimination victories in the workplace delivered during the same decade.4  Recognizing that there were profits to be made, banks jumped in the game at about the same time. The banks' entry into the field helped the credit card industry continue to expand into the 1970s, but usury laws, which varied from state to state, limited the interest rate lenders could charge. The complicated mosaic of state regulations made it inconvenient and costly for banks to do business, forcing them to comply with 50 different rulebooks.1  A weak economy, coupled with rising inflation and interest rates in the 1970s, forced credit card lenders to turn away even low-risk borrowers. The widespread lack of credit was the trigger that set the stage for key landmark decisions by the U.S. Supreme Court that would dramatically change the credit industry landscape.  An anemic economy, soaring oil prices feeding inflation, and interest rates on an upward trajectory, an apt description for the first half of 2008, right? Fact is, it's exactly what happened during the 1970s, arguably the decade with the worst economic report card since the Great Depression.  Doing business in this kind of environment was challenging for credit card lenders, who were forced to turn away even low-risk borrowers. A tangled web of 50 different state laws governing usury limits, or interest-rate caps, was overly complicated and costly for banks and other lenders. They wanted to make credit more widely available.  A series of pivotal court rulings and legal precedents reversed longstanding laws that protected borrowers from usury, effectively lifting the ceiling on credit card interest rates.  In 1978, the U.S. Supreme Court heard the case of Marquette National Bank of Minneapolis v. First Omaha Service Corp. The court found that the National Banking Act of 1864 allowed a bank to charge its credit card customers the highest interest rate permitted in the bank's home state, regardless of where customers lived.1 In other words, 'lex loci,' or local law, ruled. Credit card lenders began moving their base of operations to those states, notably Delaware and South Dakota; in South Dakota, where plans were already afoot to eliminate usury laws to stimulate the local economy, the governor welcomed these moves because they provided thousands of jobs.2 Not wanting to lose tax revenue, individual states began lowering their own usury rates in a bid to keep lending institutions from leaving. Ultimately, the entire market became deregulated in this fashion.  Billionaire investor George Soros blames the Reagan administration's zeal for deregulation for planting the seeds of today's financial crisis. By 1980, he said, the laissez-faire attitude that markets would 'self-correct' created the housing bubble that led to troubles in today's credit markets.3  In 1982, the St. Germain Depository Institutions Act became law. This law gave greater powers to federally chartered savings and loan banks (S&amp;amp;L), enabling them to diversify their business dealings to increase profits. This came after a decade of wildly fluctuating interest rates, which destabilized S&amp;amp;Ls; interest-rate caps that were in place at the time prevented S&amp;amp;Ls from paying competitive rates on deposits, so each time rates rose, customers withdrew funds en masse to chase higher returns elsewhere.4  'Something' had to be done, and that meant loosening the government regulations on S&amp;amp;Ls that had kept them from diversifying into credit cards and real estate loans.5 Rampant speculation led to a booming real estate market, followed by a crash, the infamous S&amp;amp;L crisis, and a $600 billion taxpayer-funded bailout a la George H. W. Bush, just seven years after banking deregulation.5  In 1996, in Smiley v. Citibank, the U.S. Supreme Court found that the National Banking Act of 1864 permitted credit card issuers to charge fees to credit card holders who were late in their monthly payments and that these fees were a form of interest, greatly expanding the original scope of the Marquette decision.  Relaxed government restrictions on lenders came about as state and federal laws evolved in response to the economic challenges of the day. This opened the doors to industry growth and competition, and in turn made credit cards more widely accessible to consumers at all income levels. But deregulation also had a dark side and a decidedly anti-consumer bent that persists today.  Footnotes  1 'The Deregulation of Usury Ceilings, Rise of Easy Credit and Increasing Consumer Debt,' South Dakota Law Review, Spring 2008  2 'Secret History of the Credit Card,' Frontline, PBS, November 3, 2004  3 'Soros Sees Additional Market Declines After Reprieve,' Bloomberg, April 3, 2008  4 'The S&amp;amp;L Crisis: A Chrono-Bibliography,' Federal Deposit Insurance Corporation Website  5 'Banking Crisis and Reform,' The Social Studies Help Center  Author Resource:-&gt; Dawn Handschuh has earned a living putting pen to paper for 25 years, including 10 years in financial services, where she wrote widely on retirement planning and personal finance. Dawn is a regular contributor at CreditFYI.com  and blogs on  Credit and Personal Finance Blog  Article From Article Explosion  Firefox users please select/copy/paste as usual  
